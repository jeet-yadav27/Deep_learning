{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "9DyHm-LrqqVi"
      ],
      "authorship_tag": "ABX9TyOtSwc5MLOykIyefaWjKyvu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeet-yadav27/Deep_learning/blob/main/7_Develop_MLP_Time_Series.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V73Fhy7QqX7G"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "g8U7MHs63xOZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Keras libraries you've imported: Model, Input, Dense, and concatenate. Here's a breakdown of their roles in building neural networks with Keras:\n",
        "\n",
        "keras.models.Model\n",
        "\n",
        "This is the core class for defining a Keras model. There are two main ways to create a model:\n",
        "Sequential API: Suitable for simple, linear stacks of layers (as used in earlier parts of your code).\n",
        "Functional API: More flexible for complex models with multiple inputs, outputs, or shared layers (what you're likely moving towards now).\n",
        "keras.layers.Input\n",
        "\n",
        "Used in the Functional API to define an input layer for your model. It specifies the shape of the data your model will receive.\n",
        "keras.layers.Dense\n",
        "\n",
        "Represents a fully connected layer, where each neuron receives input from all neurons of the previous layer. Common arguments include:\n",
        "units: The number of neurons in the layer.\n",
        "activation: The activation function to apply (e.g., 'relu', 'sigmoid', 'softmax').\n",
        "input_dim (for the first layer): The number of input features.\n",
        "keras.layers.concatenate\n",
        "\n",
        "Used to merge the outputs of multiple layers into a single tensor. This is essential in models with multiple input branches or when combining features from different parts of the network.\n",
        "Example using the Functional API\n",
        "\n",
        "Here's a basic example of how you might use these components together to create a model with two input branches:\n",
        "\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, concatenate\n",
        "\n",
        "### Define input layers\n",
        "input1 = Input(shape=(10,))\n",
        "input2 = Input(shape=(5,))\n",
        "\n",
        "### Define branches\n",
        "branch1 = Dense(32, activation='relu')(input1)\n",
        "branch2 = Dense(16, activation='relu')(input2)\n",
        "\n",
        "### Merge branches\n",
        "merged = concatenate([branch1, branch2])\n",
        "\n",
        "### Output layer\n",
        "output = Dense(1, activation='sigmoid')(merged)\n",
        "\n",
        "### Create the model\n",
        "model = Model(inputs=[input1, input2], outputs=output)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy')"
      ],
      "metadata": {
        "id": "s9_dMiYI3xQ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##How to Develop MLPs for Time Series\n",
        "Forecasting"
      ],
      "metadata": {
        "id": "WHa1oqRAqYkB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tutorial Overview"
      ],
      "metadata": {
        "id": "zC8i7J7Yqiw6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Univariate MLP Models\n",
        "2. Multivariate MLP Models\n",
        "3. Multi-step MLP Models\n",
        "4. Multivariate Multi-step MLP Models"
      ],
      "metadata": {
        "id": "5HNVSNYzqiy7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Univariate MLP Models"
      ],
      "metadata": {
        "id": "9DyHm-LrqqVi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Data Preparation\n",
        "2. MLP Model"
      ],
      "metadata": {
        "id": "jpYPbDU-rUG3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1- Data Preparation"
      ],
      "metadata": {
        "id": "xH7KMKELre1X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split a univariate sequence into samples\n",
        "def split_sequence(sequence, n_steps):\n",
        "    X, y = list(), list()\n",
        "    for i in range(len(sequence)):\n",
        "        # Find the end of this pattern\n",
        "        end_ix = i + n_steps\n",
        "\n",
        "        # Check if we are beyond the sequence\n",
        "        if end_ix > len(sequence) - 1:\n",
        "            break\n",
        "\n",
        "        # Gather input and output parts of the pattern\n",
        "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
        "        X.append(seq_x)\n",
        "        y.append(seq_y)\n",
        "\n",
        "    return array(X), array(y)\n",
        "\n",
        "# Define input sequence\n",
        "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
        "\n",
        "# Choose a number of time steps\n",
        "n_steps = 3\n",
        "\n",
        "# Split into samples\n",
        "X, y = split_sequence(raw_seq, n_steps)\n",
        "\n",
        "# Summarize the data\n",
        "for i in range(len(X)):\n",
        "    print( X[i],  y[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beYNNmHiqZyO",
        "outputId": "aabc3f4d-66ff-4348-c78e-c460ac580980"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10 20 30] 40\n",
            "[20 30 40] 50\n",
            "[30 40 50] 60\n",
            "[40 50 60] 70\n",
            "[50 60 70] 80\n",
            "[60 70 80] 90\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. MLP Model"
      ],
      "metadata": {
        "id": "BfCSuckpuBKv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "model = Sequential()\n",
        "model.add(Dense(100, activation='relu', input_dim=n_steps))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "# fit model\n",
        "model.fit(X, y, epochs=2000, verbose=0)\n",
        "# demonstrate prediction\n",
        "x_input = array([70, 80, 90])\n",
        "x_input = x_input.reshape((1, n_steps))\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "print(yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twyfsvPTuDMF",
        "outputId": "d1e0b349-b270-44e4-fc39-e92d0c766cc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[101.12477]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(yhat) # Prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubxH-sI2uw5K",
        "outputId": "859efc95-112b-4239-88dc-37b41b7dcd5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[101.12477]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Multivariate MLP Models"
      ],
      "metadata": {
        "id": "kcQYsvcyu5Z5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Multiple Input Series.\n",
        "2. Multiple Parallel Series."
      ],
      "metadata": {
        "id": "rJRZmXewvAzh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Multiple Input Series"
      ],
      "metadata": {
        "id": "meMO9kHHvo-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import array\n",
        "from numpy import hstack\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "metadata": {
        "id": "-5oHfSKKz1Fw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import array\n",
        "from numpy import hstack\n",
        "\n",
        "# Split a multivariate sequence into samples\n",
        "def split_sequences(sequences, n_steps):\n",
        "    X, y = list(), list()\n",
        "    for i in range(len(sequences)):\n",
        "        # Find the end of this pattern\n",
        "        end_ix = i + n_steps\n",
        "\n",
        "        # Check if we are beyond the dataset\n",
        "        if end_ix > len(sequences):\n",
        "            break\n",
        "\n",
        "        # Gather input and output parts of the pattern\n",
        "        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n",
        "        X.append(seq_x)\n",
        "        y.append(seq_y)\n",
        "\n",
        "    return array(X), array(y)\n",
        "\n",
        "# Define input sequences\n",
        "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
        "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
        "out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
        "\n",
        "# Convert to [rows, columns] structure\n",
        "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
        "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
        "out_seq = out_seq.reshape((len(out_seq), 1))\n",
        "\n",
        "# Horizontally stack columns\n",
        "dataset = hstack((in_seq1, in_seq2, out_seq))\n",
        "\n",
        "# Choose a number of time steps\n",
        "n_steps = 3\n",
        "\n",
        "# Convert into input/output\n",
        "X, y = split_sequences(dataset, n_steps)\n",
        "print(X.shape, y.shape)\n",
        "\n",
        "# Summarize the data\n",
        "for i in range(len(X)):\n",
        "    print(X[i], y[i])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RrQKRHluyAI",
        "outputId": "36fa0722-4130-4b22-8932-094960615c34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7, 3, 2) (7,)\n",
            "[[10 15]\n",
            " [20 25]\n",
            " [30 35]] 65\n",
            "[[20 25]\n",
            " [30 35]\n",
            " [40 45]] 85\n",
            "[[30 35]\n",
            " [40 45]\n",
            " [50 55]] 105\n",
            "[[40 45]\n",
            " [50 55]\n",
            " [60 65]] 125\n",
            "[[50 55]\n",
            " [60 65]\n",
            " [70 75]] 145\n",
            "[[60 65]\n",
            " [70 75]\n",
            " [80 85]] 165\n",
            "[[70 75]\n",
            " [80 85]\n",
            " [90 95]] 185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p9eVcp8ky-2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e8-xKX_xzXVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLP Model\n",
        "Before we can\n",
        "t an MLP on this data, we must\n",
        "fatten the shape of the input samples."
      ],
      "metadata": {
        "id": "190jgUeFylMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# flatten input\n",
        "n_input = X.shape[1] * X.shape[2]\n",
        "X = X.reshape((X.shape[0], n_input))"
      ],
      "metadata": {
        "id": "bfttmsPIyqKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sQyDKjNzhow",
        "outputId": "0ecb42ac-3ca4-4835-fad1-8a2945b40a8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[10, 15, 20, 25, 30, 35],\n",
              "       [20, 25, 30, 35, 40, 45],\n",
              "       [30, 35, 40, 45, 50, 55],\n",
              "       [40, 45, 50, 55, 60, 65],\n",
              "       [50, 55, 60, 65, 70, 75],\n",
              "       [60, 65, 70, 75, 80, 85],\n",
              "       [70, 75, 80, 85, 90, 95]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#deffine the Model"
      ],
      "metadata": {
        "id": "22c-mZul0suR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(100, activation='relu', input_dim=n_input))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3TuqokR0swk",
        "outputId": "56e57c55-5ef0-4601-ee1a-5dd82d8a97ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fit model\n",
        "model.fit(X, y, epochs=2000, verbose=0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJSxoIF9ziAc",
        "outputId": "551390b2-06fc-4cbd-e7a1-0e6f7f13b9c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ac3b10f1060>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# demonstrate prediction\n",
        "x_input = array([[80, 85], [90, 95], [100, 105]])\n",
        "x_input = x_input.reshape((1, n_input))\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "print(yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDc0cULi0Zam",
        "outputId": "07055cc3-1195-492a-969a-f691c3b28c2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[205.61015]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multi-Headed MLP MODEL"
      ],
      "metadata": {
        "id": "viN1WL_S17Hn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A multi-headed MLP (Multilayer Perceptron) model is a type of neural network architecture that extends the traditional MLP by incorporating multiple output heads or branches. Each head is responsible for predicting a specific task or output, allowing the model to learn multiple related tasks simultaneously.\n",
        "\n",
        "Architecture:\n",
        "\n",
        "1. Input Layer: Receives input data.\n",
        "2. Shared Encoder: A series of hidden layers that extract features from the input data.\n",
        "3. Multiple Output Heads: Each head consists of one or more hidden layers and an output layer, specific to each task.\n",
        "\n",
        "Example:\n",
        "\n",
        "Suppose we want to predict:\n",
        "\n",
        "1. House prices (regression task)\n",
        "2. House types (classification task: apartment, house, condo)\n",
        "3. House locations (classification task: urban, suburban, rural)\n",
        "\n",
        "Multi-Headed MLP Model:\n",
        "\n",
        "Input Layer (features: number of rooms, square footage, etc.)\n",
        "\n",
        "Shared Encoder:\n",
        "\n",
        "- Hidden Layer 1 (64 units, ReLU activation)\n",
        "- Hidden Layer 2 (32 units, ReLU activation)\n",
        "\n",
        "Output Heads:\n",
        "\n",
        "Head 1: House Prices (Regression)\n",
        "\n",
        "- Hidden Layer 3 (16 units, ReLU activation)\n",
        "- Output Layer (1 unit, linear activation)\n",
        "\n",
        "Head 2: House Types (Classification)\n",
        "\n",
        "- Hidden Layer 4 (16 units, ReLU activation)\n",
        "- Output Layer (3 units, softmax activation)\n",
        "\n",
        "Head 3: House Locations (Classification)\n",
        "\n",
        "- Hidden Layer 5 (16 units, ReLU activation)\n",
        "- Output Layer (3 units, softmax activation)\n",
        "\n",
        "Loss Functions:\n",
        "\n",
        "1. Mean Squared Error (MSE) for house prices\n",
        "2. Cross-Entropy Loss for house types and locations\n",
        "\n",
        "Training:\n",
        "\n",
        "The model is trained on a dataset containing input features and corresponding outputs for each task. The loss functions are combined using weighted sums or other techniques to balance the importance of each task.\n",
        "\n",
        "Benefits:\n",
        "\n",
        "1. Improved performance on individual tasks due to shared feature learning.\n",
        "2. Reduced overfitting by leveraging relationships between tasks.\n",
        "3. Efficient use of parameters, as shared encoder is used across tasks."
      ],
      "metadata": {
        "id": "vFDXaXe017J8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nshX6TE62oMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model requires input to be provided as a list of two elements, where each element in\n",
        "the list contains data for one of the submodels. In order to achieve this, we can split the 3D\n",
        "input data into two separate arrays of input data: that is from one array with the shape [7, 3,\n",
        "2] to two 2D arrays with the shape [7, 3]."
      ],
      "metadata": {
        "id": "Zuy8SfDS2ok4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import array\n",
        "from numpy import hstack\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "#from keras.layers.merge import\n",
        "from keras.layers import concatenate # Updated import statement\n",
        "\n",
        "# Split a multivariate sequence into samples\n",
        "def split_sequences(sequences, n_steps):\n",
        "    X, y = list(), list()\n",
        "    for i in range(len(sequences)):\n",
        "        # Find the end of this pattern\n",
        "        end_ix = i + n_steps\n",
        "\n",
        "        # Check if we are beyond the dataset\n",
        "        if end_ix > len(sequences):\n",
        "            break\n",
        "\n",
        "        # Gather input and output parts of the pattern\n",
        "        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n",
        "        X.append(seq_x)\n",
        "        y.append(seq_y)\n",
        "\n",
        "    return array(X), array(y)\n",
        "\n",
        "# Define input sequence\n",
        "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
        "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
        "out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
        "\n",
        "# Convert to [rows, columns] structure\n",
        "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
        "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
        "out_seq = out_seq.reshape((len(out_seq), 1))\n",
        "\n",
        "# Horizontally stack columns\n",
        "dataset = hstack((in_seq1, in_seq2, out_seq))\n",
        "\n",
        "# Choose a number of time steps\n",
        "n_steps = 3\n",
        "\n",
        "# Convert into input/output\n",
        "X, y = split_sequences(dataset, n_steps)\n",
        "\n",
        "# Separate input data\n",
        "X1 = X[:, :, 0]\n",
        "X2 = X[:, :, 1]\n",
        "\n",
        "# First input model\n",
        "visible1 = Input(shape=(n_steps,))\n",
        "dense1 = Dense(100, activation='relu')(visible1)\n",
        "\n",
        "# Second input model\n",
        "visible2 = Input(shape=(n_steps,))\n",
        "dense2 = Dense(100, activation='relu')(visible2)\n",
        "\n",
        "# Merge input models\n",
        "merge = concatenate([dense1, dense2])\n",
        "output = Dense(1)(merge)\n",
        "\n",
        "# Define model\n",
        "model = Model(inputs=[visible1, visible2], outputs=output)\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Fit model\n",
        "model.fit([X1, X2], y, epochs=2000, verbose=0)\n",
        "\n",
        "# Demonstrate prediction\n",
        "x_input = array([[80, 85], [90, 95], [100, 105]])\n",
        "x1 = x_input[:, 0].reshape((1, n_steps))\n",
        "x2 = x_input[:, 1].reshape((1, n_steps))\n",
        "yhat = model.predict([x1, x2], verbose=0)\n",
        "\n",
        "# Print prediction\n",
        "print(yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-10WaO10Zcg",
        "outputId": "c14288e0-6a94-448b-8216-8dca7688b5e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[205.87367]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "eWdjsL7J4jsx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Multiple Parallel Series"
      ],
      "metadata": {
        "id": "aUXp86PA4jv7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import array\n",
        "from numpy import hstack\n",
        "\n",
        "# Split a multivariate sequence into samples\n",
        "def split_sequences(sequences, n_steps):\n",
        "    X, y = list(), list()\n",
        "    for i in range(len(sequences)):\n",
        "        # Find the end of this pattern\n",
        "        end_ix = i + n_steps\n",
        "\n",
        "        # Check if we are beyond the dataset\n",
        "        if end_ix > len(sequences) - 1:\n",
        "            break\n",
        "\n",
        "        # Gather input and output parts of the pattern\n",
        "        seq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix, :]\n",
        "        X.append(seq_x)\n",
        "        y.append(seq_y)\n",
        "\n",
        "    return array(X), array(y)\n",
        "\n",
        "# Define input sequences\n",
        "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
        "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
        "out_seq = array([in_seq1[i] + in_seq2[i] for i in range(len(in_seq1))])\n",
        "\n",
        "# Convert to [rows, columns] structure\n",
        "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
        "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
        "out_seq = out_seq.reshape((len(out_seq), 1))\n",
        "\n",
        "# Horizontally stack columns\n",
        "dataset = hstack((in_seq1, in_seq2, out_seq))\n",
        "\n",
        "# Choose a number of time steps\n",
        "n_steps = 3\n",
        "\n",
        "# Convert into input/output\n",
        "X, y = split_sequences(dataset, n_steps)\n",
        "print(\"X Shape:\", X.shape)\n",
        "print(\"y Shape:\", y.shape)\n",
        "\n",
        "# Summarize the data\n",
        "for i in range(len(X)):\n",
        "    print(X[i], y[i])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdoYDFhy4-qT",
        "outputId": "86161304-9807-4949-e94f-5a1e2045f933"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X Shape: (6, 3, 3)\n",
            "y Shape: (6, 3)\n",
            "[[10 15 25]\n",
            " [20 25 45]\n",
            " [30 35 65]] [40 45 85]\n",
            "[[20 25 45]\n",
            " [30 35 65]\n",
            " [40 45 85]] [ 50  55 105]\n",
            "[[ 30  35  65]\n",
            " [ 40  45  85]\n",
            " [ 50  55 105]] [ 60  65 125]\n",
            "[[ 40  45  85]\n",
            " [ 50  55 105]\n",
            " [ 60  65 125]] [ 70  75 145]\n",
            "[[ 50  55 105]\n",
            " [ 60  65 125]\n",
            " [ 70  75 145]] [ 80  85 165]\n",
            "[[ 60  65 125]\n",
            " [ 70  75 145]\n",
            " [ 80  85 165]] [ 90  95 185]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Vector- Output MLP"
      ],
      "metadata": {
        "id": "pFhHzvx-6T4o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are now ready to\n",
        "t an MLP model on this data"
      ],
      "metadata": {
        "id": "Ogxw3dpf6uc6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model output will be a vector, with one element for each of the three di\n",
        "erent time\n",
        "series"
      ],
      "metadata": {
        "id": "Xiy_ks9N6mNT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# flatten input\n",
        "n_input = X.shape[1] * X.shape[2]\n",
        "X = X.reshape((X.shape[0], n_input))\n",
        "n_output = y.shape[1]"
      ],
      "metadata": {
        "id": "eVTZsgmZ7BYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nphv4dsp7Iic",
        "outputId": "b78aed1f-6ee0-4adb-bbad-5a2e1b924b91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Dense(100, activation='relu', input_dim=n_input))\n",
        "model.add(Dense(n_output))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "# fit model\n",
        "model.fit(X, y, epochs=2000, verbose=0)\n",
        "# demonstrate prediction\n",
        "x_input = array([[70,75,145], [80,85,165], [90,95,185]])\n",
        "x_input = x_input.reshape((1, n_input))\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "print(yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOexv0Zb7Ba6",
        "outputId": "41b6634d-e499-4971-c042-9b8f13bcad9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 99.999916 104.999916 205.00098 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multi-Output MLP Model"
      ],
      "metadata": {
        "id": "JshHZRrN8RHs"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xHKnmZfT-GTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import array\n",
        "from numpy import hstack\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "\n",
        "# Split a multivariate sequence into samples\n",
        "def split_sequences(sequences, n_steps):\n",
        "    X, y = list(), list()\n",
        "    for i in range(len(sequences)):\n",
        "        # Find the end of this pattern\n",
        "        end_ix = i + n_steps\n",
        "\n",
        "        # Check if we are beyond the dataset\n",
        "        if end_ix > len(sequences) - 1:\n",
        "            break\n",
        "\n",
        "        # Gather input and output parts of the pattern\n",
        "        seq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix, :]\n",
        "        X.append(seq_x)\n",
        "        y.append(seq_y)\n",
        "\n",
        "    return array(X), array(y)\n",
        "\n",
        "# Define input sequences\n",
        "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
        "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
        "out_seq = array([in_seq1[i] + in_seq2[i] for i in range(len(in_seq1))])\n",
        "\n",
        "# Convert to [rows, columns] structure\n",
        "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
        "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
        "out_seq = out_seq.reshape((len(out_seq), 1))\n",
        "\n",
        "# Horizontally stack columns\n",
        "dataset = hstack((in_seq1, in_seq2, out_seq))\n",
        "\n",
        "# Choose a number of time steps\n",
        "n_steps = 3\n",
        "\n",
        "# Convert into input/output\n",
        "X, y = split_sequences(dataset, n_steps)\n",
        "\n",
        "# Flatten input\n",
        "n_input = X.shape[1] * X.shape[2]\n",
        "X = X.reshape((X.shape[0], n_input))\n",
        "\n",
        "# Define number of outputs\n",
        "n_output = y.shape[1]\n",
        "\n",
        "# separate output\n",
        "y1 = y[:, 0].reshape((y.shape[0], 1))\n",
        "y2 = y[:, 1].reshape((y.shape[0], 1))\n",
        "y3 = y[:, 2].reshape((y.shape[0], 1))\n",
        "# define model\n",
        "visible = Input(shape=(n_input,))\n",
        "\n",
        "dense = Dense(100, activation='relu')(visible)\n",
        "# define output 1\n",
        "output1 = Dense(1)(dense)\n",
        "# define output 2\n",
        "output2 = Dense(1)(dense)\n",
        "# define output 2\n",
        "output3 = Dense(1)(dense)\n",
        "# tie together\n",
        "model = Model(inputs=visible, outputs=[output1, output2, output3])\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "# fit model\n",
        "model.fit(X, [y1,y2,y3], epochs=2000, verbose=0)\n",
        "# demonstrate prediction\n",
        "x_input = array([[70,75,145], [80,85,165], [90,95,185]])\n",
        "x_input = x_input.reshape((1, n_input))\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "print(yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rw5RR40z-GV-",
        "outputId": "f35a6239-ab74-4a8e-d074-34c0245b5377"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[100.90562]], dtype=float32), array([[106.528114]], dtype=float32), array([[207.68948]], dtype=float32)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.4 Multi-step MLP Models"
      ],
      "metadata": {
        "id": "GQfgsdCoGeLu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preparation"
      ],
      "metadata": {
        "id": "08AJwTh7GmkM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this We been to Set the Three Input Variable to make the prediction of Next Two Variable"
      ],
      "metadata": {
        "id": "61-JCH9DHC6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Univariate multi-step vector-output MLP example\n",
        "\n",
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Split a univariate sequence into samples\n",
        "def split_sequence(sequence, n_steps_in, n_steps_out):\n",
        "    X, y = list(), list()\n",
        "    for i in range(len(sequence)):\n",
        "        # Find the end of this pattern\n",
        "        end_ix = i + n_steps_in\n",
        "        out_end_ix = end_ix + n_steps_out\n",
        "\n",
        "        # Check if we are beyond the sequence\n",
        "        if out_end_ix > len(sequence):\n",
        "            break\n",
        "\n",
        "        # Gather input and output parts of the pattern\n",
        "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n",
        "        X.append(seq_x)\n",
        "        y.append(seq_y)\n",
        "\n",
        "    return array(X), array(y)\n",
        "\n",
        "# Define input sequence\n",
        "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
        "\n",
        "# Choose a number of time steps\n",
        "n_steps_in, n_steps_out = 3, 2\n",
        "\n",
        "# Split into samples\n",
        "X, y = split_sequence(raw_seq, n_steps_in, n_steps_out)\n",
        "\n",
        "# Define model\n",
        "model = Sequential()\n",
        "model.add(Dense(100, activation='relu', input_dim=n_steps_in))\n",
        "model.add(Dense(n_steps_out))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Fit model\n",
        "model.fit(X, y, epochs=2000, verbose=0)\n",
        "\n",
        "# Demonstrate prediction\n",
        "x_input = array([70, 80, 90])\n",
        "x_input = x_input.reshape((1, n_steps_in))\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "\n",
        "print(yhat)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0Q6GFtrGomG",
        "outputId": "2cec35cc-3194-4149-a483-d3b05c201732"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[103.99346  116.641624]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yAPYEBKTJHEQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.5 Multivariate Multi-step MLP Models"
      ],
      "metadata": {
        "id": "Sg5SnnaGJHGw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Multiple Input Multi-step Output.\n",
        "2. Multiple Parallel Input and Multi-step Output."
      ],
      "metadata": {
        "id": "FmSgu7rEJYRo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.5.1 Multiple Input Multi-step Output"
      ],
      "metadata": {
        "id": "O5q33UkNJ8lU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# multivariate multi-step mlp example\n",
        "from numpy import array\n",
        "from numpy import hstack\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
        "    X, y = list(), list()\n",
        "    for i in range(len(sequences)):\n",
        "        # find the end of this pattern\n",
        "        end_ix = i + n_steps_in\n",
        "        out_end_ix = end_ix + n_steps_out - 1\n",
        "\n",
        "        # check if we are beyond the dataset\n",
        "        if out_end_ix > len(sequences):\n",
        "            break\n",
        "\n",
        "        # gather input and output parts of the pattern\n",
        "        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1:out_end_ix, -1]\n",
        "        X.append(seq_x)\n",
        "        y.append(seq_y)\n",
        "\n",
        "    return array(X), array(y)\n",
        "\n",
        "# define input sequence\n",
        "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
        "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
        "out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
        "# convert to [rows, columns] structure\n",
        "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
        "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
        "out_seq = out_seq.reshape((len(out_seq), 1))\n",
        "# horizontally stack columns\n",
        "dataset = hstack((in_seq1, in_seq2, out_seq))\n",
        "# choose a number of time steps\n",
        "n_steps_in, n_steps_out = 3, 2\n",
        "# convert into input/output\n",
        "X, y = split_sequences(dataset, n_steps_in, n_steps_out)\n",
        "# flatten input\n",
        "n_input = X.shape[1] * X.shape[2]\n",
        "X = X.reshape((X.shape[0], n_input))\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Dense(100, activation='relu', input_dim=n_input))\n",
        "model.add(Dense(n_steps_out))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "# fit model\n",
        "model.fit(X, y, epochs=2000, verbose=0)\n",
        "# demonstrate prediction\n",
        "x_input = array([[70, 75], [80, 85], [90, 95]])\n",
        "x_input = x_input.reshape((1, n_input))\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "print(yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lN3TLKtuJIsh",
        "outputId": "385b0ec9-4fd1-48b3-e387-2cf8d318e4e5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[186.86073 208.58675]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ilSpwrTCL32V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.5.2 Multiple Parallel Input and Multi-step Output"
      ],
      "metadata": {
        "id": "HVF1eDScL344"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8MgRQcpCL459"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Multivariate multi-step MLP example\n",
        "\n",
        "from numpy import array\n",
        "from numpy import hstack\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Split a multivariate sequence into samples\n",
        "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
        "    X, y = list(), list()\n",
        "    for i in range(len(sequences)):\n",
        "        # find the end of this pattern\n",
        "        end_ix = i + n_steps_in\n",
        "        out_end_ix = end_ix + n_steps_out\n",
        "\n",
        "        # check if we are beyond the dataset\n",
        "        if out_end_ix > len(sequences):\n",
        "            break\n",
        "\n",
        "        # gather input and output parts of the sequence\n",
        "        seq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix:out_end_ix, :]\n",
        "        X.append(seq_x)\n",
        "        y.append(seq_y)\n",
        "\n",
        "    return array(X), array(y)\n",
        "\n",
        "# Define input sequence\n",
        "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
        "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
        "out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
        "\n",
        "# Convert to [rows, columns] structure\n",
        "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
        "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
        "out_seq = out_seq.reshape((len(out_seq), 1))\n",
        "\n",
        "# Horizontally stack columns\n",
        "dataset = hstack((in_seq1, in_seq2, out_seq))\n",
        "\n",
        "# Choose a number of time steps\n",
        "n_steps_in, n_steps_out = 3, 2\n",
        "\n",
        "# Convert into input/output\n",
        "X, y = split_sequences(dataset, n_steps_in, n_steps_out)\n",
        "\n",
        "# Flatten input\n",
        "n_input = X.shape[1] * X.shape[2]\n",
        "X = X.reshape((X.shape[0], n_input))\n",
        "\n",
        "# Flatten output\n",
        "n_output = y.shape[1] * y.shape[2]\n",
        "y = y.reshape((y.shape[0], n_output))\n",
        "\n",
        "# Define model\n",
        "model = Sequential()\n",
        "model.add(Dense(100, activation='relu', input_dim=n_input))\n",
        "model.add(Dense(n_output))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Fit model\n",
        "model.fit(X, y, epochs=2000, verbose=0)\n",
        "\n",
        "# Demonstrate prediction\n",
        "x_input = array([[60, 65, 125], [70, 75, 145], [80, 85, 165]])\n",
        "x_input = x_input.reshape((1, n_input))\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "print(yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueJ9qvToL48Q",
        "outputId": "ef9d28ce-9e1e-47eb-bfbb-147d812e0cc0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7fd810ef9870> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 91.11308  96.57112 186.98349 100.90645 107.41045 208.92159]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "s6zsBBLnPrFu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's a theoretical explanation of developing MLP models for univariate, multivariate, and multi-step time series forecasting, highlighting the differences:\n",
        "\n",
        "Univariate Time Series Forecasting\n",
        "\n",
        "- Forecasting a single variable based on its past values.\n",
        "- Goal: Predict future values of the same variable.\n",
        "\n",
        "MLP Architecture:\n",
        "\n",
        "1. Input Layer: Lagged values of the single variable (e.g., t-1, t-2, ..., t-n).\n",
        "2. Hidden Layers: Nonlinear transformations (e.g., ReLU, Tanh).\n",
        "3. Output Layer: Single forecasted value.\n",
        "\n",
        "Key Considerations:\n",
        "\n",
        "1. Lag selection: Choose relevant lagged values.\n",
        "2. Window size: Determine the number of past values.\n",
        "3. Model complexity: Balance between underfitting and overfitting.\n",
        "\n",
        "Example:\n",
        "\n",
        "Forecasting daily temperature using past temperature values.\n",
        "\n",
        "Multivariate Time Series Forecasting\n",
        "\n",
        "- Forecasting multiple variables based on their past values and relationships.\n",
        "- Goal: Predict future values of multiple variables.\n",
        "\n",
        "MLP Architecture:\n",
        "\n",
        "1. Input Layer: Lagged values of multiple variables (e.g., temperature, humidity, wind).\n",
        "2. Hidden Layers: Nonlinear transformations.\n",
        "3. Output Layer: Multiple forecasted values.\n",
        "\n",
        "Key Considerations:\n",
        "\n",
        "1. Feature selection: Choose relevant variables.\n",
        "2. Correlation analysis: Understand relationships between variables.\n",
        "3. Model complexity: Balance between underfitting and overfitting.\n",
        "\n",
        "Example:\n",
        "\n",
        "Forecasting daily temperature, humidity, and wind using past values of these variables.\n",
        "\n",
        "Multi-Step Time Series Forecasting\n",
        "\n",
        "- Forecasting multiple future values of a variable(s) based on past values.\n",
        "- Goal: Predict multiple future values.\n",
        "\n",
        "MLP Architecture:\n",
        "\n",
        "1. Input Layer: Lagged values of the variable(s).\n",
        "2. Hidden Layers: Nonlinear transformations.\n",
        "3. Output Layer: Multiple forecasted values (e.g., t+1, t+2, ..., t+n).\n",
        "\n",
        "Key Considerations:\n",
        "\n",
        "1. Horizon selection: Choose the number of future steps.\n",
        "2. Sequence-to-sequence modeling: Use encoder-decoder architectures.\n",
        "3. Error accumulation: Address compounding errors.\n",
        "\n",
        "Example:\n",
        "\n",
        "Forecasting daily temperature for the next 7 days using past temperature values.\n",
        "\n",
        "Comparison of MLP Architectures:\n",
        "\n",
        "|  | Univariate | Multivariate | Multi-Step |\n",
        "| --- | --- | --- | --- |\n",
        "| Input | Single variable | Multiple variables | Single/Multiple variables |\n",
        "| Output | Single value | Multiple values | Multiple values |\n",
        "| Complexity | Lower | Higher | Higher |\n",
        "| Considerations | Lag selection, window size | Feature selection, correlation | Horizon selection, sequence-to-sequence |\n",
        "\n",
        "In summary:\n",
        "\n",
        "- Univariate MLPs focus on a single variable's past values.\n",
        "- Multivariate MLPs consider multiple variables and their relationships.\n",
        "- Multi-step MLPs predict multiple future values, addressing sequence-to-sequence challenges.\n",
        "\n",
        "When developing MLP models, consider the specific characteristics of your time series data and adjust the architecture accordingly."
      ],
      "metadata": {
        "id": "VPD7VNYMPrII"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0RvBtGIXPr36"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}